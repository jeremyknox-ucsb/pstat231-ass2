---
title: "Homework 2"
author: "JEREMY KNOX PSTAT 231, W19"
date: "February 10, 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
graphics: yes
geometry: margin=0.75in
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, 
                      cache=FALSE, 
                      fig.width=5, 
                      fig.height=5,
                      fig.align='center')
indent1 = '    '      
indent2 = paste(rep(indent1, 2), collapse='')
```

```{r Load Appropriate Libraries, message=FALSE, warning=FALSE, include=FALSE}
require(tidyverse)
require(tree)
require(plyr)
require(class)
require(rpart)
require(maptree)
require(ROCR)
```

```{r Loading Data, warning=FALSE, results='hide', message=FALSE, include=FALSE}
spam <- read_table2("spambase.tab", guess_max=2000)
spam <- spam %>% 
    mutate(y = factor(y, levels=c(0,1), labels=c("good", "spam"))) %>%   # label as factors
    mutate_at(.vars=vars(-y), .funs=scale)                               # scale others
```

```{r Classification Error Rate, include=FALSE}
calc_error_rate <- function(predicted.value, true.value){
  return(mean(true.value!=predicted.value))
}
```

```{r DF "Records" to Capture Results, include=FALSE}
records = matrix(NA, nrow=3, ncol=2)
colnames(records) <- c("train.error","test.error")
rownames(records) <- c("knn","tree","logistic")
```

```{r Splitting Data into Training and Tests Sets, results="hide", include=FALSE}
set.seed(1)
test.indices = sample(1:nrow(spam), 1000)
spam.train=spam[-test.indices,]
spam.test=spam[test.indices,]
```

```{r 10 Fold Cross Validation, include=FALSE}
nfold = 10
set.seed(2)
folds = seq.int(nrow(spam.train)) %>%       ## sequential obs ids
    cut(breaks = nfold, labels=FALSE) %>%   ## sequential fold ids
    sample                                  ## random fold ids
```

# K-Nearest Neighbor Method
#### Problem 1: Cross Validation 10 times with do chunk for each nieghbor (K) to find best K
```{r include=FALSE}
kvec = c(1, seq(10,50,length.out=5))
```

```{r 90,indent=indent1,message=F,warning=F, include=FALSE}
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
  
  train = (folddef!=chunkid)
  
  Xtr = Xdat[train,]
  Ytr = Ydat[train]
  
  Xvl = Xdat[!train,]
  Yvl = Ydat[!train]

  ## get classifications for current training chunks
  predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
  
  ## get classifications for current test chunk
  predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
  
  data.frame(train.error = calc_error_rate(predYtr, Ytr),
             val.error = calc_error_rate(predYvl, Yvl))
}
```

```{r echo=FALSE}
XSpamTr = spam.train %>%  select(-y)
YSpamTr = spam.train$y

error_tbl = NULL

set.seed(3)
for(k in kvec){
  tmp <- ldply(1:nfold, do.chunk,folddef=folds, Xdat=XSpamTr, Ydat=YSpamTr, k=k) # stores fold, train.error, val.error
  tmp$neighbor <- k # create variable to keep track of k
  error_tbl <- rbind(error_tbl,tmp) # combine into existing table
}
error_tbl
```

```{r echo=FALSE}
error_avg = error_tbl %>% 
  group_by(neighbor) %>% 
  summarise_all(mean) 
error_avg

best_k <- error_avg$neighbor[which(error_avg$val.error==min(error_avg$val.error))] 
best_k  

```
BEST K = 10  


#### Problem 2: Find error on optimal K
```{r echo=FALSE}
set.seed(4)
XSpamTest = spam.test %>% select(-y)
YSpamTest = spam.test$y

# Fit predicted valies for train and test 
predYtr = knn(train=XSpamTr, test=XSpamTr, cl=YSpamTr, k=best_k)
predYvl = knn(train=XSpamTr, test=XSpamTest, cl=YSpamTr, k=best_k)

# Calculate errors based on error_rate function
knn.train.err = calc_error_rate(predYtr, YSpamTr)
knn.test.err = calc_error_rate(predYvl, YSpamTest)

# Add to Records DF
records[1,] = cbind(knn.train.err, knn.test.err) 
records
```


# Decision Tree Method
#### Problem 3: Make Tree
```{r echo=FALSE, include=FALSE}
set.seed(5)
spam.tree = tree(as.factor(y)~., 
                data=spam.train, 
                control=tree.control(nrow(spam.train), 
                minsize=5, 
                mindev=1e-5))
summary(spam.tree)
```
Terminal Nodes 184  
Misclassified Training Observations 48  


#### Problem 4: Pruning the Tree
```{r echo=FALSE, fig.width=10, fig.height=6}
spam.tree.pruned = prune.tree(spam.tree, best=10, method="misclass")
plot(spam.tree.pruned)
text(spam.tree.pruned, cex=.75)
```

#### Problem 5: 10-Fold Cross Validation on Tree. Size vs. Misclassification Error
```{r echo=FALSE}
set.seed(6)
cv_spam.tree.pruned = cv.tree(spam.tree, rand=folds, FUN=prune.misclass, K=nfolds)
best.size.cv = min(cv_spam.tree.pruned$size[which(cv_spam.tree.pruned$dev==min(cv_spam.tree.pruned$dev))])
best.size.cv # 76

plot(cv_spam.tree.pruned$size, cv_spam.tree.pruned$dev, type='b',
     xlab="Size of Tree",ylab="Misclassification Error", 
     col='red',main="Tree Pruning CV Plot")
abline(v=best.size.cv, lty=2)
text(best.size.cv, 500, best.size.cv, pos=1)
```

#### Problem 6: Training and Test Errors
```{r echo=FALSE}
spam.tree.pruned = prune.tree(spam.tree, best=best.size.cv, method="misclass")
spam.tree.pruned.train = predict(spam.tree.pruned, spam.train, type="class")
spam.tree.pruned.test = predict(spam.tree.pruned, spam.test, type="class")

prune.train.err = calc_error_rate(spam.tree.pruned.train, YSpamTr)
prune.test.err = calc_error_rate(spam.tree.pruned.test, YSpamTest)

records[2,] = cbind(prune.train.err, prune.test.err)
records
```

# Logisitc Regression
#### Problem 7:
###### a. Logit Function
Let $p(z)=\frac{e^z}{1+e^z}=p$, then
$$
\begin{aligned}
    e^z&=p+pe^z\\
    e^z(1-p)&=p\\
    e^z&=\frac{p}{1-p}\\
    z&=ln(\frac{p}{1-p})
\end{aligned}
$$
Thus, $ z(p)=ln(\frac{p}{1-p})$.

###### b. Link Function
Assume $z = \beta_0 + \beta_1 x_1$ and $p = logistic(z)$ from above and $\text{odds: } \frac{p}{1-p}$, then
$$
\begin{aligned}
    \frac{p}{1-p}&=\frac{\frac{e^z}{1+e^z}}{1-\frac{e^z}{1+e^z}}\\
    &=\frac{\frac{e^z}{1+e^z}}{\frac{1}{1+e^z}}\\
    &=e^z\\
\end{aligned}
$$
Which implies $\text{odds } = e^{\beta_0} e^{\beta_1 x_1}$  

Let $2x_1$, then we have
$$
\begin{aligned}
    &=\frac{e^{\beta_0} e^{\beta_1 (x_1+2)}}{e^{\beta_0} e^{\beta_1 x_1}}\\
    &=e^{2 \beta_1}
\end{aligned}
$$
Thus a two times increase of $x_1$ gives us $2x_1 \implies e^{2 \beta_1}$.


For $\beta_1 < 0$, what does $p$ approach as $x_1 \rightarrow \infty$? We have $p = \frac{e^{\beta_0} e^{\beta_1 x_1}}{1+e^{\beta_0} e^{\beta_1 x_1}}$
$$
\begin{aligned}
    \lim_{x_1\to\infty} p &=\frac{\lim_{x_1\to\infty} e^{\beta_0} e^{\beta_1 x_1}}{1+\lim_{x_1\to\infty} e^{\beta_0} e^{\beta_1 x_1}}\\
    &= \frac{0}{1+0}\\
    &= 0\\
\end{aligned}\\
$$
Thus we have, $p$ approaches $0$ as $x_1 \rightarrow \infty$.

For $\beta_1 < 0$, what does $p$ approach as $x_1 \rightarrow -\infty$? We have $p = \frac{e^{\beta_0} e^{\beta_1 x_1}}{1+e^{\beta_0} e^{\beta_1 x_1}}$
$$
\begin{aligned}
    \lim_{x_1\to\infty} p &=\frac{\lim_{x_1\to\infty} e^{\beta_0} e^{\beta_1 x_1}}{\lim_{x_1\to\infty}1+e^{\beta_0} e^{\beta_1 x_1}}\\
    &= \frac{\infty}{\infty}\\
\end{aligned}\\
$$
Apply L'Hospital $\mathop {\lim }\limits_{x \to c} \frac{{f\left( x \right)}}{{g\left( x \right)}} = \mathop {\lim }\limits_{x \to c} \frac{{f'\left( x \right)}}{{g'\left( x \right)}}$:
$$
\begin{aligned}
    \lim_{x_1\to\infty} p &= \lim_{x_1\to\infty}\frac{e^{\beta_0} \beta_1 e^{\beta_1 x_1}}{e^{\beta_0} \beta_1 e^{\beta_1 x_1}}\\
    &= \lim_{x_1\to\infty} 1\\
    &= 1\\
\end{aligned}\\
$$
Thus, $p$ approaches $1$ as $x_1 \rightarrow -\infty$.


#### Problem 8: Classify with Logistic and obtain Training and Test Error
```{r echo=FALSE, warning=FALSE}
glm.logit = glm(y~., data=spam.train, family="binomial") 

glm.pred.train = predict.glm(glm.logit, spam.train, type="response")
train.good.pred = glm.pred.train>0.5 # classified "good"
train.good.real = spam.train$y=="spam" # actual "good"
(err.table = with(spam.train, table(train.good.pred, train.good.real))) # confusion matrix of pred v actual
(glm.train.error = 1-((err.table[1]+err.table[4])/sum(err.table)))

glm.pred.test = predict.glm(glm.logit, spam.test, type="response")
test.good.pred = glm.pred.test>0.5 # classified "good"
test.good.real = spam.test$y=="spam" # actual "good"
(err.table = with(spam.test, table(test.good.pred, test.good.real))) # confusion matrix of pred v actual
(glm.test.error = 1-((err.table[1]+err.table[4])/sum(err.table)))

# Add to RECORDS
records[3,] = cbind(glm.train.error, glm.test.error)
records
```
TREE model has lowest test.error of 0.061  


#### Problem 9: ROC Curves for Tree v Logistic
```{r , echo=FALSE}
prob.tree = predict(spam.tree.pruned, spam.test, type="vector") # predicted probabilities for each obeservation from spam.test
pred.tree = prediction(prob.tree[,2], spam.test$y) # predict outcomes from prob.tree
perf.tree = performance(pred.tree, measure="tpr", x.measure="fpr")

prob.glm = predict(glm.logit, spam.test, type="response") # predicted probabilities for each obeservation from spam.test
pred.glm = prediction(prob.glm, spam.test$y) # predict outcomes from prob.glm
perf.glm = performance(pred.glm, measure="tpr", x.measure="fpr")

plot(perf.tree, col='brown', lwd=2, main="ROC Curve for Decision Tree & Logistic Regression")
plot(perf.glm, col='red', lwd=2, add=TRUE)
abline(0,1)
legend("bottomright", legend=c("Decision Tree", "Logistic Regression"), col=c("brown", "red"),lty=1)

(tree.auc <- performance(pred.tree, "auc")@y.values) # 0.9578583
(glm.auc <- performance(pred.glm, "auc")@y.values) # 0.9758875

# Looks like the logistic model wins with a higher AUC. 
```


#### Problem 10:
When considering time spent on email, efficieny and accuracy are usually negatively correlated. However, accuracy oftern supersedes efficieny. Thus false positives would be the main concern. Emails that get marked as "spam" that are not can be very bad for the customer of this spam filter. 


#### Problem 11: Multivariate Normal  
If $\hat{Y}=1$, then $P(Y=1|X=x) > T$
$$
\begin{aligned}
      \frac{f_1(x) \pi_1}{f_1(x) \pi_1 + f_2(x) \pi_2} &> T\\
      \frac{1}{1+\frac{f_2(x) \pi_2}{f_1(x) \pi_1}} &> T\\
      \frac{1}{T} &> 1+\frac{f_2(x) \pi_2}{f_1(x) \pi_1}\\
      \frac{1-T}{T} &> \frac{f_2(x) \pi_2}{f_1(x) \pi_1}\\
      log(\pi_1)+log(f_1(x))-log(\pi_2)-log(f_2(x)) &> log(\frac{T}{1-T}) \\
      \text{expanding the log we get} \\ 
      log(f_k(x)) &= -\frac{1}{2}log(|\Sigma_{k}^{-1}|)+log(\pi_k) \\
      \text{substituting in } log(f_k(x)) \  k=1,2 \\
              - \frac{1}{2}(x-\mu_1)^T\Sigma_{1}^{-1}(x-\mu_1) -\frac{1}{2}log(|\Sigma_{1}^{-1}|)+log(\pi_1)\\
        + \frac{1}{2}(x-\mu_2)^T\Sigma_{2}^{-1}(x-\mu_2) +\frac{1}{2}log(|\Sigma_{2}^{-1}|)-log(\pi_2) &> log(\frac{T}{1-T})\\
        \delta_1(x)-\delta_2(x) &> log(\frac{T}{1-T})\\
\end{aligned}\\
$$
Let $M(T) = log(\frac{T}{1-T})$, then $\delta_1(x)-\delta_2(x) > M(T)$. When the thresshold $p = \frac{1}{2}, \text{then } M(\frac{1}{2})=log\Bigg( \frac{\frac{1}{2}}{1-\frac{1}{2}} \Bigg) = 0$. When the probability threshold is $\frac{1}{2}$ we have a decision threshold of $0$.



```{r 14-0, warning=FALSE, echo=FALSE}
algae = read.table("algaeBloom.txt",na.strings="XXXXXXX") # load data, fill in empty strings
colnames = c('season','size','speed','mxPH','mnO2','Cl','NO3','NH4','oPO4','PO4','Chla','a1','a2','a3','a4','a5','a6','a7') # set column names
colnames(algae) = colnames
algae = as_tibble(algae)  %>% 
  select(-(a2:a7)) # remove a2:a7 columns
```


#### Problem 12: Variable Standardization and Discretization
```{r warning=FALSE}
algae = mutate_at(algae, vars(colnames[4:11]), 
                   funs(log(.))) # log transform
algae = mutate_at(algae, vars(colnames[4:11]),  
                       funs(ifelse(is.na(.), median(algae$.,na.rm=TRUE), .))) # repalce NA's with medians
algae = mutate_at(algae, vars(a1), funs(ifelse(.>0.5,"High","Low"))) # a1 as factor
```


#### Problem 13. Linear and Quadratic Discriminant Analysis
###### a) LDA
```{r , echo=FALSE}
algae.lda = MASS::lda(a1~., data=algae, CV=TRUE)
algae.lda.pred = prediction(algae.lda$posterior[,2], algae$a1)
algae.lda.perf = performance(algae.lda.pred, measure="tpr", x.measure="fpr")
```

###### b) QDA
```{r ,echo=FALSE}
algae.qda = MASS::qda(a1~., data=algae, CV=TRUE)
algae.qda.pred = prediction(algae.qda$posterior[,2], algae$a1)
algae.qda.perf = performance(algae.qda.pred, measure = 'tpr', x.measure = 'fpr')

plot(algae.lda.perf, col='brown', lwd=2)
plot(algae.qda.perf, col='red', lwd=2, add=TRUE)
legend("bottomright", legend=c("LDA", "QDA"), col=c("brown", "red"),lty=1)
abline(0,1) 

(algae.lda.auc <- performance(algae.lda.pred, "auc")@y.values) # 0.7517825
(algae.qda.auc <- performance(algae.qda.pred, "auc")@y.values) # 0.7534406
```
AUC of QDA is 0.753 vs. LDA of 0.751, thus the "better" model is QDA.   
   
     
       
       
       
       
       
       



